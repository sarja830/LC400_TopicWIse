## Multithreading

### How a process works:
Hello folks.

Today I want to talk to you about multithreading. At a very high level, I'm going to go over what it is and why we want to use it. I wanted to create a video on multithreading because if you're new to the concept of multithreading, it sounds really scary. In reality, multithreading is a very practical and straightforward concept. In short, multithreading enables us to do parallel computing efficiently. Let's start our explanation of multithreading by first discussing how a process works. When you start a program, it is first loaded and given an address space in main memory from your hard disk. After being loaded in memory, it is then scheduled onto an available CPU. When a process is scheduled onto a CPU, the process instructions are executed sequentially. Take, for example, this simple program which prints out Hello World to the console. When we run this program, the CPU will execute each line of the program sequentially, and it will keep track of which instruction it is about to execute by using what's known as a program counter.

The program counter represents part of an execution context. An execution context is the current state of a running process, which includes data like what instruction the CPU is currently executing. If you have multiple CPUs, and even in the case of a single CPU, you could have multiple execution contexts within a single process. We refer to these execution contexts in an abstract data structure called a thread.

A process can have one or more threads.

These threads can execute simultaneously on multiprocessor and multicore systems, and execute different sections of the program. In contrast to a thread, a process is allocated an address space. In the case of a thread, a thread shares its parent process's address space along with any other threads that the parent process has created. In this way, threads are considered a lightweight option to a process, because they will almost always consume less memory than a new process would. In this diagram, we see that process 2 has several threads. There is also a variable x that process 2 created. All three of the threads in process 2 have the ability to read and write to the memory location where variable x is located. If variable x were to be incremented every time we completed a for loop iteration within process 2, there's a possibility that each of these threads may increment the variable. As the programmer, we have no control over which thread accesses variable x, and when it accesses variable x. The reason for this is that the operating system's scheduler schedules processes and threads according to its scheduling algorithm. Whatever scheduling algorithm is on our operating system, that's what we have to use. This can cause really nasty issues in multithreaded programs. In order to implement multithreaded programs, we almost certainly have to use what's known as a synchronization construct. There are many, but some of the most common are mutexes and semaphores. These mechanisms enforce synchronization between threads.

So if thread 1 in process 2 is currently updating variable x with a new value, no other threads will be allowed to update variable x while thread 1 is updating it. I said earlier that multithreading allows us to perform parallel computing efficiently. We could very well have instead of threads multiple processes running on multiple CPUs.

In doing so, we can avoid the problem of synchronization between threads in a multithreaded process because each process has its own address space that other processes are not allowed to write to, and the operating system actively prevents them from doing this. However, address spaces can be very large, and we may only need to run a portion of the program rather than all of it each time we run it. If we were to create many processes to perform parallel computing, we would quickly use up the memory on most any machine. This is why threads are useful, because they utilize the address space of the parent process, making better use of the system's memory and consuming less space. The benefits of multithreading still outweigh the disadvantage of having to implement synchronization between threads. One of the most common examples of multithreading is in the case of a web server.

If we have a web server that is serving a static website, in other words, some HTML files, when the web server receives an HTTP GET request, it will provide those files to the requesting client. The web server, like any program, will execute its instructions sequentially when it receives a request. However, the web server may receive multiple requests for those HTML files at the same time. If it does, those requests are queued and have to wait for the server to complete requests that it has already received. Thankfully, most web servers today are multithreaded, and the server will either create a pool of threads or dynamically create new threads when an HTTP GET request is received. That's why when you visit sites like Facebook and Amazon, you typically receive a response almost immediately. Otherwise, if those servers weren't multithreaded, you would literally have to wait in a queue until the server handled everyone's requests who visited the site before you. I hope this explanation of multithreading helped give you a better understanding of the concept and that it made you eager to learn more. If so, please throw a like on the video and let me know in the comments if I've missed anything or if there is any particular topic you would like me to cover.

Thanks for watching.

